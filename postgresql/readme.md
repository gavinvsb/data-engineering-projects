````markdown
# Sparkify ETL Project

## ğŸ“Œ Project Overview
A startup called **Sparkify** wants to analyze the data theyâ€™ve been collecting on songs and user activity from their new music streaming app.  

Currently, the data is stored as:
- **JSON logs** containing user activity events.  
- **JSON metadata** containing information about songs.  

The analytics team is especially interested in **understanding what songs users are listening to**, but querying raw JSON files is inefficient.  

To solve this, we:  
1. Designed a **relational database schema** (star schema).  
2. Built an **ETL pipeline** in Python to transform and load the data into PostgreSQL.  

---

## ğŸš€ How to Run the Project

1. **Create the database and tables**  
```bash
python create_tables.py
````

2. **Run the ETL pipeline to process data and populate tables**

```bash
python etl.py
```

---

## ğŸ“‚ Repository Structure

* **[data/](data/)** â†’ JSON files with song metadata and user activity logs.
* **create\_tables.py** â†’ Script to create/recreate the database schema.
* **sql\_queries.py** â†’ Contains all SQL statements used by the ETL pipeline.
* **etl.py** â†’ ETL pipeline to extract, transform, and load data into PostgreSQL.

---

## ğŸ—„ï¸ Database Schema Design

The schema follows a **star schema** optimized for analytics:

* **Fact Table**

  * `songplays` â†’ Records user song play events (filtered by `page = 'NextSong'`).

* **Dimension Tables**

  * `users` â†’ App users.
  * `songs` â†’ Song metadata.
  * `artists` â†’ Artist information.
  * `time` â†’ Timestamps broken down into specific time units.

This design allows Sparkify to efficiently analyze user listening behavior across multiple dimensions (time, users, artists, and songs).

---

## ğŸ”„ ETL Pipeline

The ETL pipeline:

1. **Extracts** data from song and log JSON files.
2. **Transforms** it into structured format aligned with the star schema.
3. **Loads** it into PostgreSQL tables for analytics.

---

## ğŸ“Š Dataset

The project uses two datasets:

1. **Song Dataset**

   * Subset of the [Million Song Dataset](http://millionsongdataset.com/).
   * Each JSON file contains metadata about a single song and its artist.
   * Files are partitioned by the first three letters of each songâ€™s track ID.

   Example file paths:

   ```
   data/song_data/A/B/C/TRABCEI128F424C983.json
   data/song_data/A/A/B/TRAABJL12903CDCF1A.json
   ```

2. **Log Dataset**

   * JSON log files generated by the app based on user activity (e.g., song plays).
   * Used to populate the `songplays` fact table and the `users` and `time` dimension tables.

---

```
```
